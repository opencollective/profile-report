{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from database export and reformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure dictionary\n",
    "\n",
    "fig_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv, sql query that generated this csv is queries/user_cohort_table_query.sql\n",
    "df = pd.read_csv('data/user_activity_cohort_table_2023-09-09T14_17_51.117818Z.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "c = [\n",
    "    'UserId',\n",
    "    'UserSlug',\n",
    "    'Expense Activities',\n",
    "    'Expense Hosts',\n",
    "    'Expense to Own Collective Activities',\n",
    "    'Expense to Own Collective Hosts',\n",
    "    'Host Admin Activities',\n",
    "    'Host Admin Hosts',\n",
    "    'Collective Admin Activities',\n",
    "    'Collective Admin Hosts',\n",
    "    'Direct Contributions',    \n",
    "    'Direct Contributions Hosts',\n",
    "    'Direct Contributions Recipients',\n",
    "    'Collective Contributions',\n",
    "    'Collective Contributions Hosts',\n",
    "    'Collective Contributions Recipients',\n",
    "    'Contributions to Own Collective',\n",
    "    'Contributions to Own Collective Hosts',\n",
    "    'Contributions to Own Collective Recipients',\n",
    "    'Contributions Via Host',\n",
    "    'Contributions Via Host Hosts',\n",
    "    'Contributions Via Host Recipients',\n",
    "    'Event Orders',\n",
    "    'Event Orders Hosts',\n",
    "    'Event Orders Recipients',\n",
    "    'Organization Contributions',\n",
    "    'Organization Contributions Hosts',\n",
    "    'Organization Contributions Recipients',\n",
    "    'Virtual Card Purchases',\n",
    "    'Virtual Card Purchases Hosts'\n",
    "]\n",
    "df = df[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate lists of collectives\n",
    "\n",
    "stringlists = [\n",
    "'Collective Contributions Hosts',\n",
    "'Collective Contributions Recipients',\n",
    "'Direct Contributions Hosts',\n",
    "'Direct Contributions Recipients',\n",
    "'Contributions to Own Collective Hosts',\n",
    "'Contributions to Own Collective Recipients',\n",
    "'Contributions Via Host Hosts',\n",
    "'Contributions Via Host Recipients',\n",
    "'Organization Contributions Hosts',\n",
    "'Organization Contributions Recipients',\n",
    "'Event Orders Hosts',\n",
    "'Event Orders Recipients',\n",
    "'Expense Hosts',\n",
    "'Expense to Own Collective Hosts',\n",
    "'Host Admin Hosts',\n",
    "'Collective Admin Hosts',\n",
    "'Virtual Card Purchases Hosts'\n",
    "]\n",
    "\n",
    "for s in stringlists:\n",
    "    df[s] = df[s].apply(lambda x: x[1:-1].split(', ') if type(x) == str else [])\n",
    "    df[s] = df[s].apply(lambda x: [] if type(x) != list else x)\n",
    "    df[s] = df[s].apply(lambda x: [i for i in x if i != ''])\n",
    "    df[s].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all columns to snake case\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "df.rename(columns={'userid': 'user_id', 'userslug': 'user_slug'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all users with any activity in the period\n",
    "\n",
    "all_users_df = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop scammy outliers and host admins with scripted activity\n",
    "\n",
    "# users sudharaka-palamakumbura and znarf have already been removed from the dataset in the sql query\n",
    "\n",
    "# if hon-community-thailand or heroes-of-newerth-community are in any of the lists, drop the row\n",
    "\n",
    "df_processed = all_users_df.copy()\n",
    "df_processed = df_processed[~df_processed['collective_contributions_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['collective_contributions_recipients'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['direct_contributions_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['direct_contributions_recipients'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['contributions_to_own_collective_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['contributions_to_own_collective_recipients'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['contributions_via_host_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['contributions_via_host_recipients'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['organization_contributions_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['organization_contributions_recipients'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['event_orders_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['event_orders_recipients'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['expense_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['expense_to_own_collective_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['host_admin_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]\n",
    "df_processed = df_processed[~df_processed['collective_admin_hosts'].apply(lambda x: 'hon-community-thailand' in x or 'heroes-of-newerth-community' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for total numbers of contributions, expenses and activities\n",
    "\n",
    "# Sum the number of Direct Contributions and Collective Contributions for each user\n",
    "df_processed['total_contributions'] = df_processed['direct_contributions'] + df_processed['collective_contributions'] + df_processed['contributions_to_own_collective'] + df_processed['contributions_via_host'] + df_processed['organization_contributions'] + df_processed['event_orders']\n",
    "\n",
    "# Sum the number of expense_activities, collective_expense_activities and Virtual Card Purchases for each user\n",
    "df_processed['total_expenses'] = df_processed['expense_activities'] + df_processed['expense_to_own_collective_activities'] + df_processed['virtual_card_purchases']\n",
    "\n",
    "# total number of activities\n",
    "df_processed['total_activities'] = df_processed['total_contributions'] + df_processed['total_expenses'] + df_processed['host_admin_activities'] + df_processed['collective_admin_activities']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep users with at least one activity of the types we're interested in\n",
    "\n",
    "counted_users_df = df_processed[df_processed['total_activities'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define active users as those with total activities > threshold\n",
    "threshold = 0\n",
    "active_users_df = counted_users_df[counted_users_df['total_activities'] > threshold].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define higly active users as those with total activities > high_threshold\n",
    "high_threshold = 11\n",
    "highly_active_users_df = counted_users_df[counted_users_df['total_activities'] > high_threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log of all activity counts\n",
    "\n",
    "ac = [\n",
    "    'expense_activities',\n",
    "    'expense_to_own_collective_activities',\n",
    "    'host_admin_activities',\n",
    "    'collective_admin_activities',\n",
    "    'direct_contributions',    \n",
    "    'collective_contributions',\n",
    "    'contributions_to_own_collective',\n",
    "    'contributions_via_host',\n",
    "    'organization_contributions',\n",
    "    'event_orders',\n",
    "    'virtual_card_purchases',\n",
    "    'total_contributions',\n",
    "    'total_expenses',\n",
    "    'total_activities'\n",
    "]\n",
    "\n",
    "# Add new columns to df with log of activity counts, named with Log prefix\n",
    "for a in ac:\n",
    "    active_users_df[a + '_log'] = np.log(active_users_df[a] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normalized log scores for each activity type\n",
    "\n",
    "# Create new columns with normalized log scores between 0 and 1, named with Norm prefix\n",
    "for a in ac:\n",
    "    active_users_df[a + '_norm_log'] = (active_users_df[a + '_log'] - active_users_df[a + '_log'].min()) / (active_users_df[a + '_log'].max() - active_users_df[a + '_log'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate score (0,1,2,3) of each user for each activity type based on normalized log\n",
    "\n",
    "# Create new columns with score 0,1,2,3 based on norm log, named with _score suffix\n",
    "# If norm log is 0, score is 0\n",
    "# If norm log is between 0 and 0.33, score is 1\n",
    "# If norm log is between 0.33 and 0.66, score is 2\n",
    "# If norm log is between 0.66 and 1, score is 3\n",
    "for a in ac:\n",
    "    active_users_df[a + '_score'] = active_users_df[a + '_norm_log'].apply(lambda x: 0 if x == 0 else 1 if x < 0.33 else 2 if x < 0.66 else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Yeo-Johnson power transform score\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "pt_std = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "\n",
    "for c in ac:\n",
    "    # Transform the columns and add them to the dataframe with name <column name> Yeojohnson\n",
    "    # And normalize the values between 0 and 1\n",
    "    active_users_df[f'{c}_yeojohnson'] = pt_std.fit_transform(active_users_df[[c]])\n",
    "    active_users_df[f'{c}_yeojohnson_scaled'] = MinMaxScaler().fit_transform(pt.fit_transform(active_users_df[[c]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns, first column is user_id, second column is user_slug, rest of columns are in alphabetical order\n",
    "active_users_df = active_users_df.reindex(sorted(active_users_df.columns), axis=1)\n",
    "active_users_df = active_users_df[['user_id', 'user_slug'] + sorted(list(set(active_users_df.columns) - set(['user_id', 'user_slug'])))]\n",
    "# reorder so that all columns that end with _host or _recipient are at the end\n",
    "host_recipient_cols = [col for col in active_users_df.columns if col.endswith('_hosts') or col.endswith('_recipients')]\n",
    "other_cols = [col for col in active_users_df.columns if col not in host_recipient_cols]\n",
    "\n",
    "# Combine both lists to get the new order\n",
    "new_order = other_cols + host_recipient_cols\n",
    "\n",
    "# Reorder DataFrame based on this new order\n",
    "active_users_df = active_users_df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns for each activity type and their corresponding score columns\n",
    "\n",
    "cols = [\n",
    "    (\"expense_activities\", \"expense_activities_score\"), \n",
    "    (\"expense_to_own_collective_activities\", \"expense_to_own_collective_score\"),\n",
    "    (\"virtual_card_purchases\", \"virtual_card_purchases_score\"),\n",
    "    (\"total_expenses\", \"total_expenses_score\"),\n",
    "    (\"host_admin_activities\", \"host_admin_activities_score\"),\n",
    "    (\"collective_admin_activities\", \"collective_admin_activities_score\"),\n",
    "    (\"direct_contributions\", \"direct_contributions_score\"),\n",
    "    (\"collective_contributions\", \"collective_contributions_score\"),\n",
    "    (\"contributions_to_own_collective\", \"contributions_to_own_collective_score\"),\n",
    "    (\"contributions_via_host\", \"contributions_via_host_score\"),\n",
    "    (\"organization_contributions\", \"organization_contributions_score\"),\n",
    "    (\"event_orders\", \"event_orders_score\"),\n",
    "    (\"total_contributions\", \"total_contributions_score\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of users in different categories\n",
    "\n",
    "all_users_number = len(all_users_df)\n",
    "counted_users_number = len(counted_users_df)\n",
    "active_users_number = len(active_users_df)\n",
    "highly_active_users_number = len(highly_active_users_df)\n",
    "\n",
    "expenses = all_users_df[all_users_df[\"expense_activities\"] > 0][\"expense_activities\"]\n",
    "expenses_to_own_collective = all_users_df[all_users_df[\"expense_to_own_collective_activities\"] > 0][\"expense_to_own_collective_activities\"]\n",
    "host_admin_activities = all_users_df[all_users_df[\"host_admin_activities\"] > 0][\"host_admin_activities\"]\n",
    "collective_admin_activities = all_users_df[all_users_df[\"collective_admin_activities\"] > 0][\"collective_admin_activities\"]\n",
    "direct_contributions = all_users_df[all_users_df[\"direct_contributions\"] > 0][\"direct_contributions\"]\n",
    "collective_contributions = all_users_df[all_users_df[\"collective_contributions\"] > 0][\"collective_contributions\"]\n",
    "contributions_to_own_collective = all_users_df[all_users_df[\"contributions_to_own_collective\"] > 0][\"contributions_to_own_collective\"]\n",
    "contributions_via_host = all_users_df[all_users_df[\"contributions_via_host\"] > 0][\"contributions_via_host\"]\n",
    "organization_contributions = all_users_df[all_users_df[\"organization_contributions\"] > 0][\"organization_contributions\"]\n",
    "event_orders = all_users_df[all_users_df[\"event_orders\"] > 0][\"event_orders\"]\n",
    "virtual_card_purchases = all_users_df[all_users_df[\"virtual_card_purchases\"] > 0][\"virtual_card_purchases\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities counted in dataset\n",
    "\n",
    "**Expense activities:** collective.expense.created\n",
    "\n",
    "**Virtual card activities:** virtualcard.purchase\n",
    "\n",
    "**Host admin activities:** collective.approved, collective.rejected, collective.expense.paid, collective.expense.incomplete, collective.expense.scheduledForPayment, collective.virtualcard.added, collective.virtualcard.deleted, collective.virtualcard.request.rejected, collective.virtualcard.request.approved, collective.expense.putOnHold, collective.expense.releasedFromHold, collective.expense.reApprovalRequested, collective.expense.unscheduledForPayment, agreement.created, agreement.edited, collective.created\n",
    "\n",
    "**Collective admin activities:** collective.apply, collective.core.member.edited, collective.core.member.removed, collective.expense.approved, collective.expense.unapproved, collective.update.created\n",
    "\n",
    "**Contributor activities:** orders updated in period where status is \"PAID\", \"ACTIVE\" or \"CANCELLED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print user activity counts\n",
    "\n",
    "print(f'Number of unique users with any activity in the period: {all_users_number}')\n",
    "print(f'Counted users, number of users with at least one counted activity: {counted_users_number}')\n",
    "print(f'Active users, number of users with at least {threshold + 1} counted activities: {active_users_number}')\n",
    "print(f'Highly active users, number of users with at least {high_threshold + 1} counted activities: {highly_active_users_number}')\n",
    "print()\n",
    "print(f'Counted activites: Host and collective admin activities, direct and collective expenses, virtual card purchases, and direct and collective contributions ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw\n",
    "\n",
    "data = dict(\n",
    "    number=[all_users_number, counted_users_number, highly_active_users_number],\n",
    "    stage=[\"All users with any activity \", \"Users with +1 counted activity \", \"Users with +12 counted activites \"])\n",
    "\n",
    "\n",
    "fig = px.funnel(data, x='number', y='stage', custom_data=['number'])\n",
    "# do not show y axis title\n",
    "fig.update_yaxes(title_text='')\n",
    "fig.show()\n",
    "\n",
    "fig_dict['active_users'] = {\n",
    "    'fig': fig, \n",
    "    'title': 'User Activity Counts', \n",
    "    'description': 'Number of users with any activity, users with at least one counted activity, and users with at least 12 counted activities',\n",
    "    'info': \"\"\"\n",
    "    <p>For 'all users' any user is counted who has any recorded activity in the activity log. This also includes signing in to the platform. For the 'counted activities' groups the following activities are counted and aggregated into activity classes:</p> <br>\n",
    "    <ul>\n",
    "    <li><b>Expense activities:</b> collective.expense.created, virtualcard.purchase </li>\n",
    "    <li><b>Host admin activities:</b> collective.approved, collective.rejected, collective.expense.paid, collective.expense.incomplete, collective.expense.scheduledForPayment, collective.virtualcard.added, collective.virtualcard.deleted, collective.virtualcard.request.rejected, collective.virtualcard.request.approved, collective.expense.putOnHold, collective.expense.releasedFromHold, collective.expense.reApprovalRequested, collective.expense.unscheduledForPayment, agreement.created, agreement.edited, collective.created </li>\n",
    "    <li><b>Collective admin activities:</b> collective.apply, collective.core.member.edited, collective.core.member.removed, collective.expense.approved, collective.expense.unapproved, collective.update.created</li>\n",
    "    <li><b>Contributor activities:</b> Not counted from the activity log as we only want to capture activities that users do on the platform, not activities that are automatic. We define a contributor activity as making or updating an order, so we count orders that are updated by the user in the period with status orders updated in period where status is \"PAID\", \"ACTIVE\" or \"CANCELLED\".</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <p>Note that some activities are not counted because they are not specific to any user class, so do not help us to identify user classes. Examples of these are rejecting an expense and posting an expense comment.</p>\n",
    "    \"\"\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print user stats for each activity type\n",
    "\n",
    "print(f'Number of users with expenses to own collectives: {expenses_to_own_collective.shape[0]}')\n",
    "print(f'         - {round(expenses_to_own_collective.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(expenses_to_own_collective.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with expenses to other collectives: {expenses.shape[0]}')\n",
    "print(f'         - {round(expenses.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(expenses.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with virtual card purchases: {virtual_card_purchases.shape[0]}')\n",
    "print(f'         - {round(virtual_card_purchases.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(virtual_card_purchases.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with host admin activities: {host_admin_activities.shape[0]}')\n",
    "print(f'         - {round(host_admin_activities.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(host_admin_activities.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with collective admin activities: {collective_admin_activities.shape[0]}')\n",
    "print(f'         - {round(collective_admin_activities.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(collective_admin_activities.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with contributions via host: {contributions_via_host.shape[0]}')\n",
    "print(f'         - {round(contributions_via_host.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(contributions_via_host.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with contributions to own collective: {contributions_to_own_collective.shape[0]}')\n",
    "print(f'         - {round(contributions_to_own_collective.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(contributions_to_own_collective.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with organization contributions: {organization_contributions.shape[0]}')\n",
    "print(f'         - {round(organization_contributions.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(organization_contributions.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with collective contributions: {collective_contributions.shape[0]}')\n",
    "print(f'         - {round(collective_contributions.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(collective_contributions.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with direct contributions: {direct_contributions.shape[0]}')\n",
    "print(f'         - {round(direct_contributions.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(direct_contributions.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()\n",
    "print(f'Number of users with event orders: {event_orders.shape[0]}')\n",
    "print(f'         - {round(event_orders.shape[0]/all_users_number*100,2)}% of all users')\n",
    "print(f'         - {round(event_orders.shape[0]/counted_users_number*100,2)}% of counted users')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate markdown for the notebook\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "fr=2\n",
    "\n",
    "md(\"# All analysis below concerns the subset of active users (n=%s) with at least %i core activities.\"%(\"{:,}\".format(active_users_number),threshold+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_yeojohnson = False\n",
    "if plot_yeojohnson:\n",
    "    # Using active_users_df, plot activity histograms and Yeo-Johnson transformation scatterplots for all activity types\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Set the Seaborn style\n",
    "    sns.set_style(\"darkgrid\")\n",
    "\n",
    "    # Create a figure and array of axes for the number of features\n",
    "    num_features = len(cols)\n",
    "    f, axarr = plt.subplots(num_features, 3, figsize=(15, 5*num_features))\n",
    "\n",
    "    for idx, c in enumerate(cols):\n",
    "\n",
    "        feature_title = c[0].replace('_', ' ').title()\n",
    "\n",
    "        # Count the number of users with at least one activity of the type we're interested in\n",
    "        num_users = active_users_df[active_users_df[c[0]] > 0].shape[0]\n",
    "\n",
    "        # Show a Pie Chart of the number of users with at least one activity\n",
    "        pie_labels = [feature_title, 'No ' + feature_title]\n",
    "        axarr[idx, 0].pie([num_users, active_users_number - num_users], autopct='%1.1f%%', startangle=90)\n",
    "        axarr[idx, 0].set_title(feature_title + ' Among Active Users')\n",
    "\n",
    "        # change color of the first slice to orange\n",
    "        axarr[idx, 0].patches[0].set_facecolor('orange')\n",
    "        # change color of the second slice to grey\n",
    "        axarr[idx, 0].patches[1].set_facecolor('grey')\n",
    "\n",
    "        axarr[idx, 0].legend(pie_labels, loc='upper center', bbox_to_anchor=(0.5, 0.10))\n",
    "        \n",
    "        # Activity Histogram using Seaborn\n",
    "        feature = active_users_df[active_users_df[c[0]] > 0][c[0]]\n",
    "        sns.histplot(data=feature, bins=np.arange(1, 21, 1), edgecolor='black', ax=axarr[idx, 1], kde=False)\n",
    "        axarr[idx, 1].set_xticks(np.arange(1, 21, 1))\n",
    "        axarr[idx, 1].set_xticklabels(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20+'])\n",
    "        axarr[idx, 1].set_title(feature_title)\n",
    "        axarr[idx, 1].set_xlabel(f'Number of {feature_title}')\n",
    "        axarr[idx, 1].set_ylabel('Number of Users')\n",
    "\n",
    "        # Yeo-Johnson Transformation Scatterplot using Seaborn\n",
    "        sns.scatterplot(x=active_users_df[c[0]], y=active_users_df[f'{c[0]}_yeojohnson'], ax=axarr[idx, 2])\n",
    "        axarr[idx, 2].set_title(f'{feature_title} vs Yeo-Johnson Transformation')\n",
    "        axarr[idx, 2].set_xlabel(feature_title)\n",
    "        axarr[idx, 2].set_ylabel(f'Yeo-Johnson Transformation')\n",
    "\n",
    "\n",
    "    # After setting your subplots\n",
    "    plt.subplots_adjust(top=0.95)  # This reduces the height of the subplot area to 90% of the figure, leaving 10% at the top for the title.\n",
    "\n",
    "    # Add space between the rows of subplots\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "activity_figs = []\n",
    "\n",
    "for idx, c in enumerate(cols):\n",
    "    feature_title = c[0].replace('_', ' ').title()\n",
    "\n",
    "    # Count the number of users with at least one activity of the type we're interested in\n",
    "    num_users = active_users_df[active_users_df[c[0]] > 0].shape[0]\n",
    "\n",
    "    # Initialize a 1x2 subplot with appropriate types\n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                        specs=[[{'type':'pie'}, {'type':'xy'}]])\n",
    "\n",
    "    # Pie Chart of the number of users with at least one activity\n",
    "    pie_data = pd.DataFrame({\n",
    "        'Activity': [feature_title, 'No ' + feature_title],\n",
    "        'Count': [num_users, active_users_number - num_users]\n",
    "    })\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=pie_data['Activity'], values=pie_data['Count'], \n",
    "               marker=dict(colors=['orange', 'grey']), showlegend=False, hovertemplate='Users with %{label}: %{value}', name=''), \n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Activity Histogram\n",
    "    feature_data = active_users_df[active_users_df[c[0]] > 0][c[0]]\n",
    "    # Group values of 20 or more together\n",
    "    feature_data = feature_data.apply(lambda x: 20 if x >= 20 else x)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=feature_data, marker_color='blue', showlegend=False,\n",
    "                     xbins=dict(start=0.5, end=21, size=1), hovertemplate='Users with %{x} activities: %{y}', name=''), \n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(tickvals=list(range(1, 21)), \n",
    "                     ticktext=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20+'], \n",
    "                     row=1, col=2,\n",
    "                     title_text=\"Activities\")\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Users\", row=1, col=2)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    activity_figs.append({\n",
    "        'fig': fig,\n",
    "        'title': feature_title,\n",
    "        'description': f'Number of users with at least one {feature_title} and histogram of number of {feature_title} per user.',\n",
    "        'info': f\"\"\"\n",
    "        <p>For {feature_title} we count the number of users who have at least one {feature_title} in the period. We also plot a histogram of the number of {feature_title} per user.</p>\n",
    "        <p>For the histogram, we group all users with 20 or more {feature_title} into the same group.</p>\n",
    "        \"\"\"\n",
    "    })\n",
    "\n",
    "    fig_dict['activity_counts'] = activity_figs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To give extra weight to host admins, add an additional column to the dataframe with the sum of host admin activities and collective admin activities\n",
    "\n",
    "active_users_df['host_admin_acivity_modifier'] = active_users_df['host_admin_activities'] + active_users_df['collective_admin_activities']\n",
    "\n",
    "# If user has less than 25 host admin activities, set modifier to 0\n",
    "active_users_df.loc[active_users_df['host_admin_activities'] < 25, 'host_admin_acivity_modifier'] = 0\n",
    "\n",
    "# Scale the modifier with Yeo-Johnson Transformation\n",
    "active_users_df['host_admin_acivity_modifier_yeojohnson'] = pt_std.fit_transform(active_users_df[['host_admin_acivity_modifier']])\n",
    "\n",
    "# Note that we add host_admin_acivity_modifier_yeojohnson to the list of features to be used for clustering, giving host admins extra weight\n",
    "\n",
    "clustering_cols = [\"expense_activities\", \"expense_to_own_collective_activities\", \"host_admin_activities\", \"collective_admin_activities\", \"direct_contributions\", \"collective_contributions\", \"contributions_to_own_collective\", \"contributions_via_host\", \"organization_contributions\", \"event_orders\", \"host_admin_acivity_modifier\"]\n",
    "clustering_features = [c + '_yeojohnson' for c in clustering_cols]\n",
    "\n",
    "# Create a dataframe with the features to be used for clustering\n",
    "cluster_df = active_users_df[clustering_features].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform k-means clustering on active users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-means clustering on users in active_users_df\n",
    "\n",
    "# Use the elbow method to determine the optimal number of clusters\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list of the number of clusters to try\n",
    "k_list = list(range(1, 20))\n",
    "\n",
    "# Create a list to store the inertia values\n",
    "inertia_list = []\n",
    "\n",
    "# For each value of k, perform k-means clustering and calculate the inertia\n",
    "for k in k_list:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=1000)\n",
    "    kmeans.fit(cluster_df)\n",
    "    inertia_list.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the inertia values for each value of k\n",
    "plt.plot(k_list, inertia_list, '-o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.xticks(k_list)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing 13 clusters because even though the elbow is at 11, trial and error with domain knowledge showed that 13 clusters gives better results\n",
    "nc = 13\n",
    "\n",
    "# Perform k-means clustering\n",
    "kmeans = KMeans(n_clusters=nc, random_state=42, n_init=10, max_iter=1000)\n",
    "kmeans.fit(cluster_df)\n",
    "\n",
    "# Add the cluster labels to the dataframe\n",
    "cluster_df['k_means_cluster'] = kmeans.labels_\n",
    "\n",
    "# add the cluster labels to the original dataframe\n",
    "active_users_df['k_means_cluster'] = kmeans.labels_ +1\n",
    "active_users_df['cluster'] = active_users_df['k_means_cluster']\n",
    "clusters = active_users_df['cluster']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set temporary cluster names\n",
    "\n",
    "cluster_names = {}\n",
    "for c in range(1,clusters.max()+1):\n",
    "    cluster_names[c] = f'Cluster {c}'\n",
    "    \n",
    "active_users_df['cluster_name'] = active_users_df['cluster'].map(cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_cols = [\"expense_activities\", \"expense_to_own_collective_activities\", \"host_admin_activities\", \"collective_admin_activities\", \"direct_contributions\", \"collective_contributions\", \"contributions_to_own_collective\", \"contributions_via_host\", \"organization_contributions\", \"event_orders\"]\n",
    "\n",
    "# Display cluster characteristics\n",
    "\n",
    "# For each cluster in active_users_df, plot all rank histograms in a single image for that cluster\n",
    "for cluster_num in range(1, clusters.max()+1):\n",
    "    print(f'Cluster {cluster_num}')\n",
    "\n",
    "    # print the number of users in the cluster\n",
    "    print(f'Number of users in cluster: {active_users_df[active_users_df[\"cluster\"] == cluster_num].shape[0]}')\n",
    "    \n",
    "    # get the cluster dataframe\n",
    "    cluster = active_users_df[active_users_df['cluster'] == cluster_num]\n",
    "    \n",
    "    # Calculate the number of rows needed based on the length of cols\n",
    "    num_rows = int(np.ceil(len(cols) / 3))\n",
    "    \n",
    "    # Create subplots for this cluster\n",
    "    fig, axes = plt.subplots(num_rows, 2, figsize=(15, 5*num_rows))  # Adjust the figsize to your needs\n",
    "\n",
    "    # Flatten axes for easy indexing\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    # For each column, plot the histogram\n",
    "    for i, c in enumerate(clustering_cols):\n",
    "        # get the non-zero values\n",
    "        feature = cluster[cluster[c] > 0][c]\n",
    "        \n",
    "        # get the labels\n",
    "        labels = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10+']\n",
    "        \n",
    "        # adjust the bins - note the slight shift for the 10 to ensure it's included in the '10+' bin\n",
    "        bins = list(range(1, 11)) + [np.inf]\n",
    "        \n",
    "        # plot the histogram with a custom histogram calculation to ensure 10+ is handled correctly\n",
    "        hist_vals, _ = np.histogram(feature, bins=bins)\n",
    "        \n",
    "        axes[i].bar(labels, hist_vals, edgecolor='black')\n",
    "        \n",
    "        # set the title\n",
    "        axes[i].set_title(c)\n",
    "        # set the x-axis label\n",
    "        axes[i].set_xlabel(f'Number of {c}')\n",
    "        # set the y-axis label\n",
    "        axes[i].set_ylabel('Number of Users')\n",
    "\n",
    "    # Adjust layout and show the combined plots for this cluster\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Display cluster name as title\n",
    "    plt.suptitle(cluster_names[cluster_num], fontsize=40)\n",
    "    # padding between the title and the plots\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set cluster names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name clusters based on their characteristics\n",
    "# This needs to be edited after the clusters have been analyzed\n",
    "\n",
    "# Create a dictionary to store the cluster names, short and full, and the activity count that is most important for that cluster\n",
    "cluster_names = {}\n",
    "cluster_names[1] = ('dir_cont_single', 'One Time Contributors')\n",
    "cluster_names[2] = ('col_ad_basic', 'Basic Collective Admins')\n",
    "cluster_names[3] = ('host_ad_basic', 'Basic Host Admins')\n",
    "cluster_names[4] = ('event_cont', 'Event Orders')\n",
    "cluster_names[5] = ('col_ad_cont_self', 'Collective Admins Contribute to Own Collectives')\n",
    "cluster_names[6] = ('org_contr', 'Organization Contributors')\n",
    "cluster_names[7] = ('exp_sub', 'Expense Submitters')\n",
    "cluster_names[8] = ('col_ad_cont_via_col', 'Collective Admins with Contributions via Collective')\n",
    "cluster_names[9] = ('host_ad_high_acti', 'Highly Active Host Admins')\n",
    "cluster_names[10] = ('col_ad_exp_self', 'Collective Admins Expenses to Own Collectives')\n",
    "cluster_names[11] = ('host_ad_mod_act', 'Moderately Active Host Admins')\n",
    "cluster_names[12] = ('dir_contr_repeat', 'Repeated Direct Contributors')\n",
    "cluster_names[13] = ('host_ad_low_act', 'Low Activity Host Admins')\n",
    "\n",
    "# Add cluster name shorthand and full name to the dataframe\n",
    "active_users_df['cluster_name'] = active_users_df['cluster'].map(lambda x: cluster_names[x][0])\n",
    "active_users_df['cluster_full_name'] = active_users_df['cluster'].map(lambda x: cluster_names[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster in cluster_name of active_users_df, calculate the mean log norm score of rows in active_users_df for each activity type\n",
    "\n",
    "activity_features = [f + '_norm_log' for f in clustering_cols]\n",
    "\n",
    "# Create a dataframe to store the median scores\n",
    "cluster_mean_scores = pd.DataFrame(columns=activity_features)\n",
    "\n",
    "# For each cluster, calculate the median score for each activity type\n",
    "for cluster_num in range(1,clusters.max()+1):\n",
    "    cluster = active_users_df[active_users_df['cluster'] == cluster_num]\n",
    "    cluster_mean_scores.loc[cluster_num] = cluster[activity_features].mean()\n",
    "\n",
    "# Add the cluster names to the dataframe\n",
    "cluster_mean_scores['cluster_name'] = cluster_mean_scores.index.map(lambda x: cluster_names[x][0])\n",
    "cluster_mean_scores['cluster_full_name'] = cluster_mean_scores.index.map(lambda x: cluster_names[x][1])\n",
    "\n",
    "# add count of users in each cluster to the dataframe cluster_mean_scores matching on cluster_name\n",
    "cluster_mean_scores['count'] = cluster_mean_scores['cluster_name'].map(active_users_df.groupby('cluster_name')['user_id'].count())\n",
    "\n",
    "# Reorder the columns\n",
    "cluster_mean_scores = cluster_mean_scores[['cluster_name', 'cluster_full_name' , 'count'] + activity_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['dir_cont_single', 'dir_contr_repeat', 'event_cont', 'org_contr', 'col_ad_basic', 'col_ad_cont_self', 'col_ad_exp_self', 'col_ad_cont_via_col', 'host_ad_basic', 'host_ad_mod_act', 'host_ad_low_act', 'host_ad_high_acti', 'exp_sub']\n",
    "# sort rows in cluster_mean_scores by cluster_name in same order as order\n",
    "cluster_mean_scores['cluster_name'] = pd.Categorical(cluster_mean_scores['cluster_name'], order)\n",
    "cluster_mean_scores = cluster_mean_scores.sort_values('cluster_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.express.colors import sample_colorscale\n",
    "\n",
    "custom_titles = [\n",
    "    \"Expense<br>to other\", \n",
    "    \"Expense<br>to own\", \n",
    "    \"Host admin\", \n",
    "    \"Collective admin\", \n",
    "    \"Direct<br>contributions\", \n",
    "    \"Collective<br>contributions\", \n",
    "    \"Contribute<br>to own\", \n",
    "    \"Contributions<br>via host\", \n",
    "    \"Organization<br>contributions\", \n",
    "    \"Event Orders\"\n",
    "    ]\n",
    "\n",
    "# for all cluster also create separate plots\n",
    "\n",
    "user_cluster_figs = []\n",
    "\n",
    "for idx, (index, row) in enumerate(cluster_mean_scores.iterrows(), start=1):\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    c = sample_colorscale('turbo', len(cluster_mean_scores)+1)\n",
    "\n",
    "    trace = go.Scatterpolar(\n",
    "        r=row[3:].tolist(),\n",
    "        theta=custom_titles,\n",
    "        fill='toself',\n",
    "        name=row['cluster_name'],\n",
    "        showlegend=False,\n",
    "        marker = dict(color = c[idx])\n",
    "    )\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "    # Update radial axis to not show tick labels and set the range for each subplot\n",
    "    fig.update_layout({\n",
    "        'polar': dict(\n",
    "            radialaxis=dict(showticklabels=False, range=[0, 0.75])\n",
    "        )\n",
    "    })\n",
    "\n",
    "    # Update layout to adjust the size of the figure based on the number of clusters and reduce margins\n",
    "    fig.update_layout(\n",
    "        height=600,\n",
    "        width=600,\n",
    "        margin=dict(t=80, b=80, r=100, l=100)\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "    cluster_fig = {\n",
    "        'fig': fig,\n",
    "        'title': f'{row[\"cluster_full_name\"]}',\n",
    "        'description': f'Average activity scores for {row[\"cluster_full_name\"]} cluster. <br> There are <b>{row[\"count\"]} users</b> in this cluster.',\n",
    "        'info': f\"\"\"\"\"\"\n",
    "    }\n",
    "\n",
    "    user_cluster_figs.append(cluster_fig)\n",
    "\n",
    "fig_dict['user_clusters'] = user_cluster_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 rows from active_users_df where collective_admin_activities > 500 and less than 1000\n",
    "active_users_df[(active_users_df['collective_admin_activities'] > 10) & (active_users_df['collective_admin_activities'] < 20)].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save active_users_df to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save active_users_df to pkl file\n",
    "active_users_df.to_pickle('active_users_df.pkl')\n",
    "\n",
    "# save fig_dict to pkl file\n",
    "with open('fig_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(fig_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
